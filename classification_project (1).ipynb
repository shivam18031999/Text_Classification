{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shivam garg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taking 20_newsgroup as my training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data1=datasets.load_files(r\"C:\\Users\\shivamGarg\\Documents\\20_newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x consist of all the document which i used for classification\n",
    "# y_train is the list of classes corresponding to each document\n",
    "x=data1.data\n",
    "Y_train=data1.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shivamGarg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# downloading stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words=(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=[]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # to remove all the special character\n",
    "    document = re.sub(r'\\W', ' ', str(x[i]))\n",
    "    \n",
    "    # to convert multiple spaces into single spaces\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # removed prefixed b\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # remove integers\n",
    "    document = re.sub(r'\\d+', '', document)\n",
    "    \n",
    "    # convert all words into lowerletter\n",
    "    document = document.lower()\n",
    "    \n",
    "    X.append(document)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating my dictionary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={}\n",
    "#document equals to each document in X\n",
    "#word_list is the list of all the words in document\n",
    "#this dictionary consist of words of lenght more than 2 and also not a stopword\n",
    "for document in X:\n",
    "    words_list=document.split()\n",
    "    for word in words_list:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        elif (len(word)>2) and (word in dictionary.keys()):\n",
    "            dictionary[word]=dictionary[word]+1\n",
    "        elif (len(word)>2):\n",
    "            dictionary[word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the dictinary\n",
    "\n",
    "a=max(dictionary.values())\n",
    "num_word=[0 for i in range(a+1)]\n",
    "frequency=[i for i in range(a+1)]\n",
    "for key in dictionary:\n",
    "    num_word[dictionary[key]]=num_word[dictionary[key]]+1\n",
    "plt.plot(num_word,frequency)\n",
    "plt.xlabel(\"num of word\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.axis([0,10000,1,100])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5408"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new dictionary named vocabulary by cleaning those words whose frequency less than cutoff frequency\n",
    "cutoff=100\n",
    "vocabulary={}\n",
    "for key in dictionary:\n",
    "    if dictionary[key]>cutoff:\n",
    "         vocabulary[key]=dictionary[key]\n",
    "feature_list=list(vocabulary.keys())\n",
    "\n",
    "# number of columns in my classification is\n",
    "len(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a numpy array of dimension( num_datapoints x num_features)\n",
    "# num_datapoints equals to number of documents\n",
    "# num_feature equal to number of keys in my vocabulary\n",
    "num_datapoints=len(X)\n",
    "num_features=len(vocabulary.keys())\n",
    "train_data=np.zeros((num_datapoints,num_features))\n",
    "\n",
    "# creating my train_data from the documnets in the list X\n",
    "i=0\n",
    "for doc in X:\n",
    "        word_list=doc.split()\n",
    "        for word in word_list:\n",
    "            if word in vocabulary.keys():\n",
    "                        pos_x=i\n",
    "                        pos_y=feature_list.index(word)\n",
    "                        train_data[pos_x][pos_y]=train_data[pos_x][pos_y]+1\n",
    "        i=i+1   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2., ..., 0., 0., 0.],\n",
       "       [0., 2., 3., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implemening Naive bayes from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit function creates a dictionary result  whose keys is classes(20 classes)\n",
    "# fit function also conatin a key named \"total_data\" which is equal to the  len of Y_train\n",
    "# result[current_class] is also a dictionary whose keys are features of train_data\n",
    "# result[current_class] conatins two more key one is \"total_count_rows\" whose value equal to number of rows corr. to that class\n",
    "# another is \"total_count_words\" which gives me the all words( sum along rows then along column) for that class\n",
    "def fit(X_train,Y_train):\n",
    "        result={}\n",
    "        class_values=set(Y_train)\n",
    "        result[\"total_data\"]=len(Y_train)\n",
    "        for current_class in class_values:\n",
    "            result[current_class]={}\n",
    "            current_class_rows=(Y_train==current_class)\n",
    "            X_train_current=X_train[current_class_rows]\n",
    "            Y_train_current=Y_train[current_class_rows]\n",
    "            result[current_class][\"total_count_rows\"]=len(Y_train_current)\n",
    "            columns_sum=np.sum(X_train_current,axis=0)\n",
    "            features_list=X_train_current.shape[1]\n",
    "            result[current_class][\"total_count_words\"]=0\n",
    "            for j in range(features_list):\n",
    "                result[current_class][j]=columns_sum[j]\n",
    "                result[current_class][\"total_count_words\"]+=columns_sum[j]\n",
    "        return result        \n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict=fit(train_data,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the prbability\n",
    "def probability(dictionary,X,current_class):\n",
    "    output = np.log(dictionary[current_class][\"total_count_rows\"]) - np.log(dictionary[\"total_data\"])\n",
    "    total_words = len(X)\n",
    "  \n",
    "    for j in range(total_words ):\n",
    "        count_current_class_with_word = dictionary[current_class][j]+1\n",
    "        count_current_class = dictionary[current_class][\"total_count_words\"] +total_words\n",
    "        current_probablity =  X[j]*(np.log(count_current_class_with_word) - np.log(count_current_class))\n",
    "        output = output + current_probablity\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the class for a particular row\n",
    "def predictSinglePoint(dictionary,X):\n",
    "    classes=dictionary.keys()\n",
    "    best_p=None\n",
    "    best_class=None\n",
    "    check=True\n",
    "    for current_class in classes:\n",
    "        if current_class==\"total_data\":\n",
    "             continue\n",
    "        current_class_prob=probability(dictionary,X,current_class)\n",
    "        if(check or current_class_prob>best_p):\n",
    "            best_p=current_class_prob\n",
    "            best_class=current_class\n",
    "        check=False\n",
    "    return best_class    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(dictionary,X_test):\n",
    "    Y_test=[]\n",
    "    for test in X_test:\n",
    "        ans=predictSinglePoint(dictionary,test)\n",
    "        Y_test.append(ans)\n",
    "    return Y_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(Y_pred,Y_true):\n",
    "        \n",
    "        count = 0\n",
    "        for i in range(len(Y_pred)):\n",
    "            if Y_pred[i] == Y_true[i]:\n",
    "                count+=1\n",
    "        return count/len(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taking mini_newsgroup as my test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data=datasets.load_files(r\"C:\\Users\\shivamGarg\\Documents\\mini_newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test consist of all the documnets for testing\n",
    "# Y_test is the list of classes corrosponds to X_test documents\n",
    "x_test=test_data.data\n",
    "Y_test=test_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test consist of clean documnets \n",
    "X_test=[]\n",
    "for i in range(len(x_test)):\n",
    "    # to remove all the special character\n",
    "    document = re.sub(r'\\W', ' ', str(x_test[i]))\n",
    "    \n",
    "    # to convert multiple spaces into single spaces\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # removed prefixed b\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # remove integers\n",
    "    document = re.sub(r'\\d+', '', document)\n",
    "    \n",
    "    # convert all words into lowerletter\n",
    "    document = document.lower()\n",
    "    \n",
    "    X_test.append(document)\n",
    "\n",
    "\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a numpy array of dimension a x b\n",
    "# a equals to number of documnets in X_test\n",
    "# b equlas to number of features \n",
    "a=len(X_test)\n",
    "b=len(list(vocabulary.keys()))\n",
    "test_data=np.zeros((a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 2., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 2., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 2., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating test_data \n",
    "i=0\n",
    "for doc in X_test:\n",
    "        word_list=doc.split()\n",
    "        for word in word_list:\n",
    "            if word in vocabulary.keys():\n",
    "                        pos_x=i\n",
    "                        pos_y=feature_list.index(word)\n",
    "                        test_data[pos_x][pos_y]=test_data[pos_x][pos_y]+1\n",
    "        i=i+1 \n",
    "test_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using training data to train inbuilt naive bayes algorithm\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Y_pred from inbuilt algoriy=thm\n",
    "Y_pred=clf.predict(test_data)\n",
    "\n",
    "# converting classes from sumbols (0-19 ) to actual class names\n",
    "names_list=data1.target_names\n",
    "print(names_list)\n",
    "\n",
    "# converting Y_test\n",
    "Y_test_class=[]\n",
    "for data in Y_test:\n",
    "        Y_test_class.append(names_list[data])\n",
    "        \n",
    "#converting Y_pred \n",
    "Y_pred_class=[]\n",
    "for data in Y_pred:\n",
    "       Y_pred_class.append(names_list[data])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test data from inbuilt algorithm 0.914\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.86      0.84       100\n",
      "           comp.graphics       0.85      0.90      0.87       100\n",
      " comp.os.ms-windows.misc       0.93      0.87      0.90       100\n",
      "comp.sys.ibm.pc.hardware       0.79      0.92      0.85       100\n",
      "   comp.sys.mac.hardware       0.92      0.90      0.91       100\n",
      "          comp.windows.x       0.98      0.83      0.90       100\n",
      "            misc.forsale       0.87      0.98      0.92       100\n",
      "               rec.autos       0.98      0.97      0.97       100\n",
      "         rec.motorcycles       0.96      0.98      0.97       100\n",
      "      rec.sport.baseball       1.00      0.98      0.99       100\n",
      "        rec.sport.hockey       0.99      0.95      0.97       100\n",
      "               sci.crypt       0.98      0.97      0.97       100\n",
      "         sci.electronics       0.93      0.93      0.93       100\n",
      "                 sci.med       0.98      0.97      0.97       100\n",
      "               sci.space       0.98      0.96      0.97       100\n",
      "  soc.religion.christian       0.97      0.99      0.98       100\n",
      "      talk.politics.guns       0.86      0.93      0.89       100\n",
      "   talk.politics.mideast       0.97      0.95      0.96       100\n",
      "      talk.politics.misc       0.83      0.72      0.77       100\n",
      "      talk.religion.misc       0.73      0.72      0.73       100\n",
      "\n",
      "               micro avg       0.91      0.91      0.91      2000\n",
      "               macro avg       0.92      0.91      0.91      2000\n",
      "            weighted avg       0.92      0.91      0.91      2000\n",
      "\n",
      "[[86  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  1 11]\n",
      " [ 0 90  3  4  0  0  1  0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  1 87  7  0  2  2  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 92  4  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  8 90  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  3  3  1 83  1  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 98  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 97  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0 98  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 98  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  1  0 95  0  0  1  1  0  0  0  1  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  0  0 97  1  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  2  1  0  1  0  0  0  0  0 93  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  2  0  0  0  0 97  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  1  0  0  0  0  0  0  0  0  0 96  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 99  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 93  0  3  2]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 95  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  3 72 13]\n",
      " [17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  3  0  6 72]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"score on test data from inbuilt algorithm\",score(Y_pred_class,Y_test_class))\n",
    "print()\n",
    "print(classification_report(Y_test_class,Y_pred_class))\n",
    "print(confusion_matrix(Y_test_class,Y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_from_scratch=predict(final_dict,test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting Y_pred_scratch\n",
    "Y_pred_from_scratch_class=[]\n",
    "for data in Y_pred_from_scratch:\n",
    "       Y_pred_from_scratch_class.append(names_list[data])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test data from scratch 0.914\n",
      "\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.83      0.86      0.84       100\n",
      "           comp.graphics       0.85      0.90      0.87       100\n",
      " comp.os.ms-windows.misc       0.93      0.87      0.90       100\n",
      "comp.sys.ibm.pc.hardware       0.79      0.92      0.85       100\n",
      "   comp.sys.mac.hardware       0.92      0.90      0.91       100\n",
      "          comp.windows.x       0.98      0.83      0.90       100\n",
      "            misc.forsale       0.87      0.98      0.92       100\n",
      "               rec.autos       0.98      0.97      0.97       100\n",
      "         rec.motorcycles       0.96      0.98      0.97       100\n",
      "      rec.sport.baseball       1.00      0.98      0.99       100\n",
      "        rec.sport.hockey       0.99      0.95      0.97       100\n",
      "               sci.crypt       0.98      0.97      0.97       100\n",
      "         sci.electronics       0.93      0.93      0.93       100\n",
      "                 sci.med       0.98      0.97      0.97       100\n",
      "               sci.space       0.98      0.96      0.97       100\n",
      "  soc.religion.christian       0.97      0.99      0.98       100\n",
      "      talk.politics.guns       0.86      0.93      0.89       100\n",
      "   talk.politics.mideast       0.97      0.95      0.96       100\n",
      "      talk.politics.misc       0.83      0.72      0.77       100\n",
      "      talk.religion.misc       0.73      0.72      0.73       100\n",
      "\n",
      "               micro avg       0.91      0.91      0.91      2000\n",
      "               macro avg       0.92      0.91      0.91      2000\n",
      "            weighted avg       0.92      0.91      0.91      2000\n",
      "\n",
      "[[86  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  1 11]\n",
      " [ 0 90  3  4  0  0  1  0  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  1 87  7  0  2  2  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 92  4  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  8 90  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  3  3  1 83  1  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 98  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 97  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0 98  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 98  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  1  0 95  0  0  1  1  0  0  0  1  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  0  0 97  1  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  2  1  0  1  0  0  0  0  0 93  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  2  0  0  0  0 97  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  1  0  0  0  0  0  0  0  0  0 96  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 99  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0 93  0  3  2]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 95  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  3 72 13]\n",
      " [17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  3  0  6 72]]\n"
     ]
    }
   ],
   "source": [
    "print(\"score on test data from scratch\",score(Y_pred_from_scratch_class,Y_test_class))\n",
    "print()\n",
    "print(classification_report(Y_test_class,Y_pred_from_scratch_class))\n",
    "print(confusion_matrix(Y_test_class,Y_pred_from_scratch_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
